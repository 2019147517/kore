train:
  sl:
    learning_rate: 0.0001
    epochs: 100
    save_path: './pretrained/supervised_learning'
    optim: ADAM
    scheduler: {'multistep': {"milestones": [30, 80], "gamma": 0.1}}
    dataset:
      data_path: './data/'
      train_val_ratio: 0.8
      num_workers: 2
      batch_size: 64
  rl:
    learning_rate: 0.0001
    episodes: 10000
    save_path: './pretrained/reinforcement_learning'
    optim: ADAM

  device: 'cpu'
  
